{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n",
      "loading is over.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(os.getcwd())\n",
    "code_path = '/root/ieee/pipeline/'\n",
    "sys.path.append(code_path)\n",
    "\n",
    "\n",
    "path = '/root/ieee/'\n",
    "\n",
    "train_transaction = pd.read_csv(path + 'train_transaction.csv')\n",
    "test_transaction = pd.read_csv(path + 'test_transaction.csv')\n",
    "\n",
    "train_identity = pd.read_csv(path + 'train_identity.csv')\n",
    "test_identity = pd.read_csv(path + 'test_identity.csv')\n",
    "print(\"loading is over.\")\n",
    "train_transaction.sort_values('TransactionDT', inplace = True)\n",
    "test_transaction.sort_values('TransactionDT', inplace = True)\n",
    "train_transaction['nulls1'] = train_transaction.isna().sum(axis=1)\n",
    "test_transaction['nulls1'] = test_transaction.isna().sum(axis=1)\n",
    "\n",
    "card_feature = [col for col in train_transaction.columns if \"card\" in col] #category\n",
    "addr_feature = [col for col in train_transaction.columns if \"addr\" in col] #category\n",
    "dist_feature = [col for col in train_transaction.columns if \"dist\" in col] #numeric\n",
    "mail_feature = [col for col in train_transaction.columns if \"email\" in col] #category\n",
    "\n",
    "c_feature = [col for col in train_transaction.columns if \"C\" in col] #numeric\n",
    "#C1-C14: counting, \n",
    "#    such as how many addresses are found to be associated with the payment card, etc. \n",
    "#The actual meaning is masked.\n",
    "d_feature = [col for col in train_transaction.columns if \"D\" in col] #numeric \n",
    "#D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "d_feature.remove('TransactionID')\n",
    "d_feature.remove('TransactionDT')\n",
    "d_feature.remove('ProductCD')\n",
    "c_feature.remove('ProductCD')\n",
    "m_feature = [col for col in train_transaction.columns if \"M\" in col] #category\n",
    "v_feature = [col for col in train_transaction.columns if \"V\" in col] #numeric\n",
    "\n",
    "train_transaction = train_transaction.loc[train_transaction.card6 != 'debit or credit'].reset_index(drop = True)\n",
    "\n",
    "C1_threshold = test_transaction.C1.mean() + test_transaction.C1.std() * 2.5\n",
    "train_transaction = train_transaction[train_transaction.C1<C1_threshold].reset_index(drop = True)\n",
    "\n",
    "# col = 'D1'\n",
    "train_transaction['Transaction_day'] = np.floor((train_transaction['TransactionDT'] / (3600 * 24) - 1))\n",
    "test_transaction['Transaction_day'] = np.floor((test_transaction['TransactionDT'] / (3600 * 24) - 1))\n",
    "c_feat = [col for col in c_feature if col not in ['C13', 'C14']]\n",
    "\n",
    "train_transaction['Transaction_day'] = np.floor((train_transaction['TransactionDT'] / (3600 * 24) - 1))\n",
    "test_transaction['Transaction_day'] = np.floor((test_transaction['TransactionDT'] / (3600 * 24) - 1))\n",
    "train_transaction['linear'] = train_transaction['Transaction_day']\n",
    "test_transaction['linear'] = test_transaction['Transaction_day']\n",
    "train_transaction['D4_new'] = train_transaction['D4']/test_transaction['linear']\n",
    "test_transaction['D4_new'] = test_transaction['D4']/test_transaction['linear']\n",
    "\n",
    "\n",
    "# prediction = pd.read_csv(path + '/sub/KFold_2019_0903_1608_0.94231_post_black:1626_white:13719_grey:378.csv')\n",
    "for col in d_feature:\n",
    "    train_transaction[col + '_new'] = train_transaction[col] - train_transaction['Transaction_day']\n",
    "    test_transaction[col + '_new'] = test_transaction[col] - test_transaction['Transaction_day']\n",
    "\n",
    "d_new_feature = [\"{}_new\".format(col) for col in d_feature if col not in ['D1']]\n",
    "second_list = [col + card_feature + ['D1_new'] for col in [['C1', 'C2'], ['C1', 'C10'], ['C1', 'C11'],\n",
    "                                                           ['C1', 'C2', 'C9', 'C10', 'C11', 'C12']] ]\n",
    "count_list = [[col] + card_feature + ['D1_new'] for col in c_feat]\n",
    "basis_list = [card_feature + addr_feature + c_feat + ['D1_new'],\n",
    "              card_feature + addr_feature + ['D1_new']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "def data_card_merged_online(train, test, col_id):\n",
    "    used = ['TransactionID', 'Transaction_day'] + col_id\n",
    "    tr = train[used + ['isFraud']]\n",
    "    ts = test[used]\n",
    "    data = pd.concat([tr, ts]).reset_index(drop = True)\n",
    "    data.isFraud.fillna(-1, inplace = True)\n",
    "    data = data.groupby(col_id).agg({k:lambda x: list(x)\n",
    "    for k in ['TransactionID'] + ['isFraud']})\n",
    "    data.columns = [\"{}_list\".format(col) for col in data.columns]\n",
    "    data.reset_index(inplace = True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def fraud_past(x):\n",
    "    # ['isFraud_list']\n",
    "    zero = x.count(0)\n",
    "    one = x.count(1)\n",
    "    minus = x.count(-1)\n",
    "    if (zero > 0) & (minus > 0) & (one > 0):\n",
    "        return 'link_grey'\n",
    "    elif (zero * minus) > 0:\n",
    "        return 'link_white'\n",
    "    elif (one * minus) > 0:\n",
    "        return 'link_black'\n",
    "    elif len(x) == 1:\n",
    "        return 'single'\n",
    "    elif (zero > 0) & (one > 0):\n",
    "        return 'grey'\n",
    "    elif zero > 0:\n",
    "        return 'white'\n",
    "    elif one > 0:\n",
    "        return 'black'\n",
    "    else:\n",
    "        return 'outlier'\n",
    "\n",
    "def fraud_list(x):\n",
    "    id_list = []\n",
    "    for i in x:\n",
    "        id_list += i\n",
    "    return list(id_list)\n",
    "\n",
    "def local_black_merge(train, test, key_id):\n",
    "    data_card = data_card_merged_online(train, test, key_id)\n",
    "    data_card['type'] = data_card['isFraud_list'].apply(fraud_past)\n",
    "    data_card['record'] = data_card['isFraud_list'].apply(lambda x: x.count(0) + x.count(1))\n",
    "\n",
    "    fraud = pd.DataFrame(\n",
    "        fraud_list(data_card.loc[data_card['type'] == 'link_black','TransactionID_list']), \n",
    "        columns = ['TransactionID'])\n",
    "    fraud['fraud_guess'] = 1\n",
    "    temp = pd.DataFrame([])\n",
    "    fraud_num = pd.merge(fraud, test[['TransactionID','isFraud']], \n",
    "                                     how = 'inner', on =['TransactionID'])\n",
    "    fraud_num['category'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'num'] = fraud_num.isFraud.sum()\n",
    "    temp.loc[0, 'ratio'] = fraud_num.isFraud.mean()\n",
    "    temp.loc[0, 'name'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'card_cat'] = 'black'\n",
    "    del data_card;gc.collect()\n",
    "    del fraud;gc.collect()\n",
    "    return fraud_num, temp\n",
    "\n",
    "def local_special_black_merge(train, test, key_id):\n",
    "    data_card = data_card_merged_online(train, test, key_id)\n",
    "    data_card['type'] = data_card['isFraud_list'].apply(fraud_past)\n",
    "    data_card['record'] = data_card['isFraud_list'].apply(lambda x: x.count(0) + x.count(1))\n",
    "\n",
    "    fraud = pd.DataFrame(\n",
    "        fraud_list(data_card.loc[(data_card['type'] == 'link_black')\n",
    "                                 & (data_card['record'] > 2)\n",
    "                                 ,'TransactionID_list']), \n",
    "        columns = ['TransactionID'])\n",
    "    fraud['special_fraud_guess'] = 1\n",
    "    temp = pd.DataFrame([])\n",
    "    fraud_num = pd.merge(fraud, test[['TransactionID','isFraud']], \n",
    "                                     how = 'inner', on =['TransactionID'])\n",
    "    fraud_num['category'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'num'] = fraud_num.isFraud.sum()\n",
    "    temp.loc[0, 'ratio'] = fraud_num.isFraud.mean()\n",
    "    temp.loc[0, 'name'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'card_cat'] = 'special_black'\n",
    "    del data_card;gc.collect()\n",
    "    del fraud;gc.collect()\n",
    "    return fraud_num, temp\n",
    "\n",
    "def local_grey_merge(train, test, key_id):\n",
    "    data_card = data_card_merged_online(train, test, key_id)\n",
    "    data_card['type'] = data_card['isFraud_list'].apply(fraud_past)\n",
    "    data_card['record'] = data_card['isFraud_list'].apply(lambda x: x.count(0) + x.count(1))\n",
    "    data_card['ratio'] = data_card['isFraud_list'].apply(lambda x: x.count(1)/(x.count(0) + x.count(1)) \n",
    "                                                         if (x.count(0) + x.count(1)) > 0 else len(x))\n",
    "    grey = pd.DataFrame(\n",
    "        fraud_list(data_card.loc[(data_card['type'] == 'link_grey') \n",
    "                                 & (data_card['record'] > 1)\n",
    "                                 & (data_card['ratio'] >= 0.9),\n",
    "                                 'TransactionID_list']), columns = ['TransactionID'])\n",
    "    grey['grey_guess'] = 1\n",
    "    temp = pd.DataFrame([])\n",
    "    fraud_num = pd.merge(grey, test[['TransactionID','isFraud']], \n",
    "                                     how = 'inner', on =['TransactionID'])\n",
    "    fraud_num['category'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'num'] = fraud_num.isFraud.sum()\n",
    "    temp.loc[0, 'ratio'] = fraud_num.isFraud.mean()\n",
    "    temp.loc[0, 'name'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'card_cat'] = 'grey'\n",
    "    del data_card;gc.collect()\n",
    "    del grey;gc.collect()\n",
    "    return fraud_num, temp\n",
    "\n",
    "def local_white_merge(train, test, key_id):\n",
    "    data_card = data_card_merged_online(train, test, key_id)\n",
    "    data_card['type'] = data_card['isFraud_list'].apply(fraud_past)\n",
    "    data_card['record'] = data_card['isFraud_list'].apply(lambda x: x.count(0) + x.count(1))\n",
    "    \n",
    "    white = pd.DataFrame(\n",
    "        fraud_list(data_card.loc[(data_card['type'] == 'link_white') & (data_card['record'] > 1),\n",
    "                                 'TransactionID_list']), columns = ['TransactionID'])\n",
    "    white['white_guess'] = 1\n",
    "    temp = pd.DataFrame([])\n",
    "    fraud_num = pd.merge(white, test[['TransactionID','isFraud']], \n",
    "                                     how = 'inner', on =['TransactionID'])\n",
    "    fraud_num['category'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'num'] = fraud_num.isFraud.sum()\n",
    "    temp.loc[0, 'ratio'] = fraud_num.isFraud.mean()\n",
    "    temp.loc[0, 'ratio'] = fraud_num.isFraud.count()\n",
    "    temp.loc[0, 'name'] = \"_\".join(key_id)\n",
    "    temp.loc[0, 'card_cat'] = 'white'\n",
    "    del data_card;gc.collect()\n",
    "    del white;gc.collect()\n",
    "    return fraud_num, temp\n",
    "\n",
    "\n",
    "def train_threshold_rule_research(tr, full_list, threshold, func):\n",
    "    feat_rule = c_feat + ['D1_new', 'TransactionID', 'Transaction_day'] + \\\n",
    "                card_feature + addr_feature + d_new_feature + ['isFraud']\n",
    "    sample_size = train_transaction.shape[0] * (1 - threshold)\n",
    "    local_tr = train_transaction.loc[:int(sample_size), feat_rule]\n",
    "    local_ts = train_transaction.loc[int(sample_size):, feat_rule]\n",
    "    print(\"simulation begin.\")\n",
    "    res = Parallel(n_jobs=8, backend = 'multiprocessing') \\\n",
    "            (delayed(func)(local_tr, local_ts, col) for col in full_list)\n",
    "    del local_tr, local_ts;gc.collect()\n",
    "    fraud_data = pd.concat([res[row][0] for row in range(len(res))], axis = 0)\n",
    "    fraud_data.drop_duplicates(['TransactionID'], inplace = True)\n",
    "    rule_list = pd.concat([res[row][1] for row in range(len(res))], axis = 0)\n",
    "    del res;gc.collect()\n",
    "    return fraud_data, rule_list\n",
    "\n",
    "from model import kfold_lightgbm\n",
    "from feature import woe_encoder, timer, mail_func, addr_func, \\\n",
    "numeric_func, identity_func, \\\n",
    "product_func, match_func,card_func, \\\n",
    "all_category_encoding, Transaction_amt_encoding, \\\n",
    "C_feature, pca_missing, date_feature, D_feature\n",
    "\n",
    "\n",
    "def time_diff(tr, ts):\n",
    "    H_move = 12\n",
    "    card_feature = [col for col in tr.columns if \"card\" in col] #category\n",
    "    addr_feature = [col for col in tr.columns if \"addr\" in col] #category\n",
    "    feat = ['TransactionID',\"P_emaildomain\", 'TransactionDT', 'TransactionAmt'] +\\\n",
    "            d_feature + card_feature + addr_feature + c_feature\n",
    "    tr_ = tr[feat]\n",
    "    ts_ = ts[feat]\n",
    "    data_train = pd.DataFrame([])\n",
    "    data_test = pd.DataFrame([])\n",
    "    tr_['cid'] = \\\n",
    "    tr[c_feat + card_feature].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    ts_['cid'] = \\\n",
    "    ts[c_feat + card_feature].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    tr_['uid'] = tr['card1'].astype(str) + \"_\" + tr['card2'].astype(str) +\\\n",
    "                        tr['card3'].astype(str) + \"_\" + tr['card4'].astype(str) +\\\n",
    "                        tr['card5'].astype(str) + \"_\" + tr['card6'].astype(str) +\\\n",
    "                        tr['addr1'].astype(str) + \"_\" + tr['addr2'].astype(str) +\\\n",
    "                        tr['P_emaildomain'].astype(str)\n",
    "    tr_['uid'] = tr['card1'].astype(str) + \"_\" + tr['card2'].astype(str) +\\\n",
    "                        tr['card3'].astype(str) + \"_\" + tr['card4'].astype(str) +\\\n",
    "                        tr['card5'].astype(str) + \"_\" + tr['card6'].astype(str) +\\\n",
    "                        tr['addr1'].astype(str) + \"_\" + tr['addr2'].astype(str) +\\\n",
    "                        tr['P_emaildomain'].astype(str)\n",
    "    ts_['uid'] = ts['card1'].astype(str) + \"_\" + ts['card2'].astype(str) +\\\n",
    "                        ts['card3'].astype(str) + \"_\" + ts['card4'].astype(str) +\\\n",
    "                        ts['card5'].astype(str) + \"_\" + ts['card6'].astype(str) +\\\n",
    "                        ts['addr1'].astype(str) + \"_\" + ts['addr2'].astype(str) +\\\n",
    "                        ts['P_emaildomain'].astype(str)\n",
    "    tr_[\"day\"] = (tr[\"TransactionDT\"] + 3600 * H_move) // (24 * 60 * 60)\n",
    "    ts_[\"day\"] = (ts[\"TransactionDT\"] + 3600 * H_move) // (24 * 60 * 60)\n",
    "    tr_['Hour'] = np.floor(tr['TransactionDT'] / 3600) % 24\n",
    "    ts_['Hour'] = np.floor(ts['TransactionDT'] / 3600) % 24\n",
    "    tr_['D1_delta'] = tr_['D1'] - tr_['day']\n",
    "    ts_['D1_delta'] = ts_['D1'] - ts_['day']\n",
    "    tr_['D2_delta'] = tr_['D2'] - tr_['day']\n",
    "    ts_['D2_delta'] = ts_['D2'] - ts_['day']\n",
    "    tr_['D10_delta'] = tr_['D10'] - tr_['day']\n",
    "    ts_['D10_delta'] = ts_['D10'] - ts_['day']\n",
    "    tr_['D15_delta'] = tr_['D15'] - tr_['day']\n",
    "    ts_['D15_delta'] = ts_['D15'] - ts_['day']\n",
    "\n",
    "    tr_['D1_delta_uid'] = tr_['D1_delta'].astype(str) + \"_\" + tr_['uid']\n",
    "    tr_['D2_delta_uid'] = tr_['D2_delta'].astype(str) + \"_\" + tr_['uid']\n",
    "    ts_['D1_delta_uid'] = ts_['D1_delta'].astype(str) + \"_\" + ts_['uid']\n",
    "    ts_['D2_delta_uid'] = ts_['D2_delta'].astype(str) + \"_\" + ts_['uid']\n",
    "\n",
    "    tr_['D10_delta_uid'] = tr_['D10_delta'].astype(str) + \"_\" + tr_['uid']\n",
    "    tr_['D15_delta_uid'] = tr_['D15_delta'].astype(str) + \"_\" + tr_['uid']\n",
    "    ts_['D10_delta_uid'] = ts_['D10_delta'].astype(str) + \"_\" + ts_['uid']\n",
    "    ts_['D15_delta_uid'] = ts_['D15_delta'].astype(str) + \"_\" + ts_['uid']\n",
    "    \n",
    "    tr_['c4_d1_id'] = \\\n",
    "    tr_[['C4', 'D1_delta'] + card_feature].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    ts_['c4_d1_id'] = \\\n",
    "    ts_[['C4', 'D1_delta'] + card_feature].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    data_train['trans_curday_Amt_cnt'] = tr_.groupby(['uid', 'day'])['TransactionAmt'].transform('count')\n",
    "    data_test['trans_curday_Amt_cnt'] = ts_.groupby(['uid', 'day'])['TransactionAmt'].transform('count')\n",
    "    # TransactionAmt相关\n",
    "    # 当天的交易次数\n",
    "    data_train['trans_curday_Amt_cnt'] = tr_.groupby(['uid', 'day'])['TransactionAmt'].transform('count')\n",
    "    data_test['trans_curday_Amt_cnt'] = ts_.groupby(['uid', 'day'])['TransactionAmt'].transform('count')\n",
    "    # 当天的交易总额\n",
    "    data_train['trans_curday_Amt_sum'] = tr_.groupby(['uid', 'day'])['TransactionAmt'].transform('sum')\n",
    "    data_test['trans_curday_Amt_sum'] = ts_.groupby(['uid', 'day'])['TransactionAmt'].transform('sum')\n",
    "    # 当天的交易最大金额\n",
    "    data_train['trans_curday_Amt_max'] = tr_.groupby(['uid', 'day'])['TransactionAmt'].transform('max')\n",
    "    data_test['trans_curday_Amt_max'] = ts_.groupby(['uid', 'day'])['TransactionAmt'].transform('max')\n",
    "    # 当天的交易最小金额\n",
    "    data_train['trans_curday_Amt_min'] = tr_.groupby(['uid', 'day'])['TransactionAmt'].transform('min')\n",
    "    data_test['trans_curday_Amt_min'] = ts_.groupby(['uid', 'day'])['TransactionAmt'].transform('min')\n",
    "    # 当天的交易平均金额\n",
    "    data_train['trans_curday_Amt_mean'] = tr_.groupby(['uid', 'day'])['TransactionAmt'].transform('mean')\n",
    "    data_test['trans_curday_Amt_mean'] = ts_.groupby(['uid', 'day'])['TransactionAmt'].transform('mean')\n",
    "    # 当天同样金额的交易次数\n",
    "    data_train['trans_curday_samAmt_cnt'] = tr_.groupby(['uid', 'day', 'TransactionAmt'])['TransactionAmt'].transform('count')\n",
    "    data_test['trans_curday_samAmt_cnt'] = ts_.groupby(['uid', 'day', 'TransactionAmt'])['TransactionAmt'].transform('count')\n",
    "\n",
    "    data_train['trans_curday_hour_max'] = tr_.groupby(['uid', 'day'])['Hour'].transform('max')\n",
    "    data_test['trans_curday_hour_max'] = ts_.groupby(['uid', 'day'])['Hour'].transform('max')\n",
    "    # 当天的交易最小Hour\n",
    "    data_train['trans_curday_hour_min'] = tr_.groupby(['uid', 'day'])['Hour'].transform('min')\n",
    "    data_test['trans_curday_hour_min'] = ts_.groupby(['uid', 'day'])['Hour'].transform('min')\n",
    "    # 当天的交易平均Hour\n",
    "    data_train['trans_curday_hour_mean'] = tr_.groupby(['uid', 'day'])['Hour'].transform('mean')\n",
    "    data_test['trans_curday_hour_mean'] = ts_.groupby(['uid', 'day'])['Hour'].transform('mean')\n",
    "\n",
    "    data = pd.concat([data_train, data_test]).reset_index(drop = True)\n",
    "    # 距离上一笔以及下一笔交易的时间差特征(seconds)\n",
    "    key_list = ['uid', 'D1_delta_uid', 'D2_delta_uid', 'c4_d1_id', 'cid']\n",
    "    values = ['TransactionDT', 'TransactionAmt', 'C13']\n",
    "    df = pd.concat([tr_, ts_]).reset_index(drop = True)\n",
    "    for key in key_list:\n",
    "        for value in values:\n",
    "            stat_temp = df[[key] + [value]].copy()\n",
    "            for i in [-2, 2, -1, 1]:\n",
    "                shift_value = stat_temp.groupby(key)[value].shift(i)\n",
    "                cname = '_'.join([key, value]) + '_diff_time{}'.format(i)\n",
    "                data[cname] = stat_temp[value] - shift_value\n",
    "    \n",
    "    key_list = ['uid', 'D1_delta_uid', 'D2_delta_uid', 'c4_d1_id', 'cid']\n",
    "    stat_temp = df[key_list + d_feature+ ['TransactionAmt', 'C13']].copy()\n",
    "    for key in key_list:\n",
    "        for col in d_feature + ['TransactionAmt', 'C13']:\n",
    "            for i in [-1, 1]:\n",
    "                shift_value = stat_temp.groupby(key)[col].shift(i)\n",
    "                cname = '_'.join([key, col]) +'_shift_time{}'.format(i)\n",
    "                data[cname] = shift_value\n",
    "    return data\n",
    "\n",
    "def FE_OP_c1_c2(df, op = 'count', df_test = None):\n",
    "    op = op.lower()\n",
    "    c1, c2 = df.columns.tolist()\n",
    "    c1c2 = 'FE_{}_({})_({})'.format(op.upper(), c1, c2)\n",
    "    \n",
    "    if df_test is not None:\n",
    "        n_train = len(df)\n",
    "        df = pd.concat([df, df_test], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    if op == 'count':\n",
    "        s = df.groupby([c1, c2])[c1].transform(op)\n",
    "    elif op in ['nunique', 'median', 'mean', 'min', 'max', 'std', 'sum', 'cumcount']:\n",
    "        s = df.groupby(c1)[c2].transform(op)\n",
    "    elif op == 'add':\n",
    "        s = df[c1] + df[c2]\n",
    "    elif op == 'diff':\n",
    "        s = df[c1] - df[c2]\n",
    "    elif op == 'mul':\n",
    "        s = df[c1] * df[c2]\n",
    "    elif op == 'div':\n",
    "        s = df[c1] / df[c2]\n",
    "    \n",
    "    if df_test is not None:\n",
    "        return c1c2, s[:n_train].reset_index(drop = True), s[n_train:].reset_index(drop = True)\n",
    "    return c1c2, s\n",
    "\n",
    "def decompose_name(col):\n",
    "    c1, c2 = col.split(')_(')\n",
    "    op, c1 = c1.split('_(')\n",
    "    op = op[3:].lower()\n",
    "    c2 = c2[:-1]\n",
    "    return op, c1, c2\n",
    "\n",
    "def name_to_fe(train, test, cols_add):\n",
    "    for col in cols_add:\n",
    "        print(col)\n",
    "        op, c1, c2 = decompose_name(col)\n",
    "        c1c2, train[col], test[col] =  FE_OP_c1_c2(train[[c1,c2]], op, test[[c1,c2]])\n",
    "    return train, test\n",
    "\n",
    "cols_add = [\n",
    "'FE_MIN_(TransactionDT)_(C1)',\n",
    " 'FE_MIN_(card2)_(C1)',\n",
    " 'FE_MIN_(card1)_(C1)',\n",
    " 'FE_MIN_(addr1)_(C1)',\n",
    " 'FE_MIN_(card1)_(C13)',\n",
    " 'FE_MIN_(card1)_(C14)',\n",
    " 'FE_MIN_(card5)_(C1)',\n",
    " 'FE_MAX_(TransactionDT)_(C1)',\n",
    " 'FE_MAX_(card2)_(C1)',\n",
    " 'FE_MAX_(card1)_(C1)',\n",
    " 'FE_MAX_(addr1)_(C1)',\n",
    " 'FE_MAX_(TransactionDT)_(C13)',\n",
    " 'FE_MAX_(P_emaildomain)_(C1)',\n",
    " 'FE_MAX_(card2)_(C13)',\n",
    " 'FE_MAX_(card1)_(C13)',\n",
    " 'FE_MAX_(TransactionDT)_(C14)',\n",
    " 'FE_MAX_(TransactionDT)_(C12)',\n",
    " 'FE_MAX_(addr1)_(C13)',\n",
    " 'FE_MAX_(card2)_(C14)',\n",
    " 'FE_MAX_(card1)_(C14)',\n",
    " 'FE_MAX_(TransactionDT)_(TransactionAmt)',\n",
    " 'FE_MAX_(card5)_(C1)']\n",
    "\n",
    "\n",
    "def amt_accumulation_summary(tr, ts):\n",
    "    v_list = ['V47', 'V244', 'V246', 'V257']\n",
    "    key = card_feature + addr_feature + c_feature + d_feature + v_list\n",
    "    df = pd.concat([tr[key + ['Transaction_day', 'TransactionDT','TransactionAmt','P_emaildomain']], \n",
    "                    ts[key + ['Transaction_day', 'TransactionDT','TransactionAmt','P_emaildomain']]]).reset_index(drop = True)\n",
    "    H_move = 0\n",
    "    df[\"Transaction_day\"] = (df[\"TransactionDT\"] + 3600 * H_move) // (24 * 60 * 60)\n",
    "    col = 'D1'\n",
    "    df[col + '_new'] = df[col] - df['Transaction_day']\n",
    "    col = 'D2'\n",
    "    df[col + '_new'] = df[col] - df['Transaction_day']\n",
    "    data = pd.DataFrame([])\n",
    "#     df['uid'] = df[card_feature + addr_feature].apply(\n",
    "#                     lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "    df['uid'] = df[card_feature + addr_feature + [\"P_emaildomain\"]].apply(\n",
    "                    lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    df['d1_uid'] = df['uid'].astype(str) + \"_\" + df['D1_new'].astype(str)\n",
    "    df['d2_uid'] = df['uid'].astype(str) + \"_\" + df['D2_new'].astype(str)\n",
    "    \n",
    "    df['c4_d1_id'] = \\\n",
    "    df[['C4', 'D1_new'] + card_feature].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    df['c14_d1_uid'] = \\\n",
    "    df[['C14', 'D1_new']+ card_feature].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    used = []\n",
    "    for key in ['uid', 'd1_uid', 'c4_d1_id']:\n",
    "        for col in ['TransactionAmt'] + ['D1']:\n",
    "            df['{}_diff_1_{}'.format(col, key)] = \\\n",
    "            df[col] - df.groupby(key)[col].shift(1)\n",
    "            df['{}_diff_-1_{}'.format(col, key)] = \\\n",
    "            df[col] - df.groupby(key)[col].shift(-1)\n",
    "            used.append(('{}_diff_1_{}'.format(col, key), key))\n",
    "            used.append(('{}_diff_-1_{}'.format(col, key), key))\n",
    "    for func in ['mean', 'std']: #19.09.17 \n",
    "        for col in used:\n",
    "            data[\"_\".join([col[0], func])] = df.groupby(col[1])[col[0]].transform(func)\n",
    "\n",
    "            \n",
    "    new_used = []\n",
    "    for key in ['uid', 'd1_uid', 'c4_d1_id']:\n",
    "#         ['C1', 'C13', 'C14'] + ['D1_new']\n",
    "        for col in ['C1', 'C14']:\n",
    "            df['{}_encoding_{}'.format(col, key)] = df[col]\n",
    "            new_used.append(('{}_encoding_{}'.format(col, key), key))\n",
    "\n",
    "    for func in ['mean', 'std']: #19.09.17 \n",
    "        for col in new_used:\n",
    "            data[\"_\".join([col[0], func])] = df.groupby(col[1])[col[0]].transform(func)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def local_training_baseline_estimation(tr, threshold):\n",
    "    features = c_feature + d_feature + dist_feature + v_feature + ['TransactionAmt','nulls1']\n",
    "    sample_size = train_transaction.shape[0] * threshold\n",
    "    local_tr = train_transaction.loc[:int(sample_size)].reset_index(drop = True)\n",
    "    local_ts = train_transaction.loc[int(sample_size):].reset_index(drop = True)\n",
    "    data = pd.DataFrame([])\n",
    "    tr_shape = local_tr.shape[0]\n",
    "    print(\"feature eng begin.\")\n",
    "    temp = mail_func(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = addr_func(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = numeric_func(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = identity_func(local_tr, local_ts,train_identity, test_identity)\n",
    "    data[temp.columns] = temp\n",
    "    temp = product_func(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = match_func(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = card_func(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = all_category_encoding(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = Transaction_amt_encoding(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = C_feature(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = date_feature(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = time_diff(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    temp = amt_accumulation_summary(local_tr, local_ts)\n",
    "    data[temp.columns] = temp\n",
    "    basic_feature = list(data.columns)\n",
    "    local_tr[data.columns] = data[:tr_shape].reset_index(drop = True)\n",
    "    local_ts[data.columns] = data[tr_shape:].reset_index(drop = True)\n",
    "    del data,temp;gc.collect()\n",
    "    print(\"over.\")\n",
    "    used = [col for col in features + basic_feature if col not in d_feature]\n",
    "    oof_train, oof_test, score_list = kfold_lightgbm(local_tr, local_ts, used)\n",
    "    result = pd.DataFrame([])\n",
    "    result['TransactionID'] = local_ts['TransactionID']\n",
    "    result['pred'] = oof_test.mean(axis = 1)\n",
    "    result['isFraud'] = local_ts['isFraud']\n",
    "    del oof_train, oof_test, score_list;gc.collect()\n",
    "    del local_tr, local_ts;gc.collect()\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def rule_evaluation(local_result, rule_list, fraud_data, fraud_exist = pd.DataFrame([]), white = False):\n",
    "    if white:\n",
    "        local_sim = pd.merge(local_result, \n",
    "                     fraud_data[['TransactionID', 'white_guess']], \n",
    "                     on = ['TransactionID'], how = 'left')\n",
    "        local_sim['pred'] = np.where(local_sim['white_guess'] == 1, 0, local_sim['pred'])\n",
    "        initial_score = roc_auc_score(local_result['isFraud'],local_result['pred'])\n",
    "        score_max = roc_auc_score(local_sim['isFraud'], local_sim['pred'])\n",
    "        boost = score_max - initial_score\n",
    "        print(\"initial score:\", initial_score)\n",
    "        print(\"Max boost:\", boost)\n",
    "        print(\"white score:\", score_max)\n",
    "        result = pd.DataFrame([])\n",
    "        result.loc[0, 'initial_score'] = initial_score\n",
    "        result.loc[0, 'boosted_score'] = score_max\n",
    "        result.loc[0, 'boost_score'] = boost\n",
    "        result.loc[[0], 'name'] = pd.Series([rule_list])\n",
    "        return fraud_data, result\n",
    "    if fraud_exist.shape[0] > 0:\n",
    "        fraud_all = fraud_exist\n",
    "        fraud_sim = local_result.copy()\n",
    "        fraud_sim = pd.merge(fraud_sim, fraud_all, on = ['TransactionID'], how = 'left')\n",
    "        fraud_sim['pred'] = np.where(fraud_sim['fraud_guess'] == 1, 1, fraud_sim['pred'])\n",
    "        initial_score = roc_auc_score(fraud_sim['isFraud'], fraud_sim['pred'])\n",
    "    else:\n",
    "        fraud_all = pd.DataFrame([])\n",
    "        initial_score = roc_auc_score(local_result['isFraud'],local_result['pred'])\n",
    "    fraud_sim = local_result.copy()\n",
    "    print(\"initial score:\", initial_score)\n",
    "    score_max = initial_score\n",
    "    rule_used = []\n",
    "    for i in rule_list['name']:\n",
    "        fraud_temp = fraud_data.loc[fraud_data['category'] == i, ['TransactionID']]\n",
    "        fraud_all = pd.concat([fraud_all, fraud_temp]).reset_index(drop = True)\n",
    "        fraud_all.drop_duplicates(['TransactionID'], inplace = True)\n",
    "        fraud_all['fraud_guess'] = 1\n",
    "        if 'fraud_guess' in fraud_sim.columns:\n",
    "            fraud_sim.drop(['fraud_guess'], axis = 1, inplace = True)\n",
    "        fraud_sim = pd.merge(fraud_sim, fraud_all, on = ['TransactionID'], how = 'left')\n",
    "        fraud_sim['pred'] = np.where(fraud_sim['fraud_guess'] == 1, 1, fraud_sim['pred'])\n",
    "        score = roc_auc_score(fraud_sim['isFraud'], fraud_sim['pred'])\n",
    "        if score > score_max:\n",
    "            score_max = score\n",
    "            rule_used.append(i)\n",
    "    print(\"refit list.\")\n",
    "    fraud_all = fraud_exist\n",
    "    for i in rule_used:\n",
    "        fraud_temp = fraud_data.loc[fraud_data['category'] == i, ['TransactionID']]\n",
    "        fraud_all = pd.concat([fraud_all, fraud_temp]).reset_index(drop = True)\n",
    "        fraud_all.drop_duplicates(['TransactionID'], inplace = True)\n",
    "        fraud_all['fraud_guess'] = 1\n",
    "    print(\"highest:\", score_max)\n",
    "    print(\"last score:\", score)\n",
    "    boost = score_max - initial_score\n",
    "    print(\"Max boost:\", boost)\n",
    "    result = pd.DataFrame([])\n",
    "    result.loc[0, 'initial_score'] = initial_score\n",
    "    result.loc[0, 'boosted_score'] = score_max\n",
    "    result.loc[0, 'boost_score'] = boost\n",
    "    result.loc[[0], 'name'] = pd.Series([rule_used])\n",
    "    return fraud_all, result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_feat = [col for col in c_feature if col not in ['C13', 'C14']]\n",
    "\n",
    "\n",
    "addr_list = [addr_feature + ['D1_new', 'D10_new'],\n",
    "            addr_feature + c_feat + ['D1_new', 'D10_new'],\n",
    "             addr_feature + ['C{}'.format(i) for i in range(1, 12, 2)] + ['D1_new', 'D10_new'],\n",
    "             addr_feature + ['C{}'.format(i) for i in range(2, 13, 2)] + ['D1_new', 'D10_new']\n",
    "            ]\n",
    "\n",
    "\n",
    "count_list = [[col] + card_feature + ['D1_new'] for col in ['C4', 'C5']]\n",
    "basis_list = [card_feature + addr_feature + c_feat + ['D1_new'],\n",
    "              card_feature + addr_feature + ['D1_new'],\n",
    "             \n",
    "             card_feature + ['C{}'.format(i) for i in range(1, 12, 2)] + ['D1_new'],\n",
    "             card_feature + ['C{}'.format(i) for i in range(2, 13, 2)] + ['D1_new']\n",
    "             ]\n",
    "second_list = [col + card_feature + ['D1_new'] for col in [['C1', 'C10'],\n",
    "                                                           ['C1', 'C2', 'C9', 'C10', 'C11', 'C12']] ]\n",
    "\n",
    "day_list =  [[col] + card_feature + ['D1_new'] for col in ['D10_new', 'D15_new']] +\\\n",
    "            [[col] + card_feature + addr_feature for random_statecol in ['D2_new', 'D4_new']] +\\\n",
    "            [[col] + card_feature + c_feat for col in ['D4_new', 'D10_new']]\n",
    "\n",
    "black_list = count_list + basis_list + second_list + day_list + addr_list\n",
    "\n",
    "count_list = [[col] + card_feature + ['D1_new'] for col in ['C12', 'C14']]\n",
    "day_list =  [[col] + card_feature + ['D1_new'] for col in ['D10_new', 'D15_new']] +\\\n",
    "            [[col] + card_feature + addr_feature for col in ['D2_new', 'D4_new']] +\\\n",
    "            [[col] + card_feature + c_feat for col in ['D4_new', 'D10_new']]\n",
    "        \n",
    "special_list = count_list + day_list + basis_list + addr_list\n",
    "\n",
    "count_list = [[col] + card_feature + ['D1_new'] for col in c_feat]\n",
    "basis_list = [card_feature + addr_feature + c_feat + ['D1_new'],\n",
    "              card_feature + addr_feature + ['D1_new'],\n",
    "             card_feature + ['C{}'.format(i) for i in range(1, 12, 2)] + ['D1_new'],\n",
    "             card_feature + ['C{}'.format(i) for i in range(2, 13, 2)]+ ['D1_new']\n",
    "              \n",
    "             ]\n",
    "\n",
    "day_list =  [[col] + card_feature + ['D1_new'] for col in ['D2_new', 'D11_new']] +\\\n",
    "             [[col] + card_feature + addr_feature for col in ['D2_new', 'D11_new']]\n",
    "#plus D11_new out of research.\n",
    "grey_list = basis_list + day_list + addr_list + count_list\n",
    "\n",
    "white_list = [card_feature + addr_feature + c_feat + ['D1_new'], card_feature + c_feat + ['D1_new']\n",
    "             ]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def local_rule_based_chosen(tr, threshold):\n",
    "    local_result = local_training_baseline_estimation(tr, threshold)\n",
    "    fraud_data1, rule_list1 = train_threshold_rule_research(tr, black_list, threshold, local_black_merge)\n",
    "    fraud_data2, rule_list2 = train_threshold_rule_research(tr, special_list, threshold, local_special_black_merge)\n",
    "    fraud_data3, rule_list3 = train_threshold_rule_research(tr, grey_list, threshold, local_grey_merge)\n",
    "    fraud_data4, rule_list4 = train_threshold_rule_research(tr, white_list, threshold, local_white_merge)\n",
    "    rule_list1.sort_values(['ratio', 'num'], ascending = False, inplace = True)\n",
    "    rule_list2.sort_values(['ratio', 'num'], ascending = False, inplace = True)\n",
    "    rule_list3.sort_values(['ratio', 'num'], ascending = False, inplace = True)\n",
    "    rule_list4.sort_values(['ratio', 'num'], ascending = False, inplace = True)\n",
    "    fraud_id, result1 = rule_evaluation(local_result, rule_list1, fraud_data1)\n",
    "    fraud_id, result2 = rule_evaluation(local_result, rule_list2, fraud_data2, fraud_id)\n",
    "    fraud_id, result3 = rule_evaluation(local_result, rule_list3, fraud_data3, fraud_id)\n",
    "    fraud_id_none, result4 = rule_evaluation(local_result, rule_list4, fraud_data4, pd.DataFrame([]), True)\n",
    "    result1.loc[0, 'card_cat'] = 'black'\n",
    "    result2.loc[0, 'card_cat'] = 'special'\n",
    "    result3.loc[0, 'card_cat'] = 'grey'\n",
    "    result4.loc[0, 'card_cat'] = 'white'\n",
    "    result = pd.concat([result1, result2, result3, result4]).reset_index(drop = True)\n",
    "    del local_result, fraud_data1, fraud_data2, fraud_data3, fraud_data4;gc.collect()\n",
    "    del rule_list1, rule_list2, rule_list3, rule_list4;gc.collect()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################threshold: 0.2\n",
      "feature eng begin.\n",
      "over.\n",
      "train.shape = (117418, 811), test.shape = (469670, 811)\n",
      "############################################################ fold = 1 / 5\n",
      "####### cur time = 2019/09/22 08:51:41\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid_0's auc: 0.908984\n",
      "[1000]\tvalid_0's auc: 0.911426\n",
      "Early stopping, best iteration is:\n",
      "[981]\tvalid_0's auc: 0.911504\n",
      "period: [    0     1     2 ... 23481 23482 23483] , the score is 0.9115044025203857\n",
      "############################################################ fold = 2 / 5\n",
      "####### cur time = 2019/09/22 08:53:17\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid_0's auc: 0.927853\n",
      "Early stopping, best iteration is:\n",
      "[822]\tvalid_0's auc: 0.928189\n",
      "period: [23484 23485 23486 ... 46965 46966 46967] , the score is 0.9281886467465198\n",
      "############################################################ fold = 3 / 5\n",
      "####### cur time = 2019/09/22 08:54:40\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid_0's auc: 0.926111\n",
      "[1000]\tvalid_0's auc: 0.929556\n",
      "Early stopping, best iteration is:\n",
      "[1049]\tvalid_0's auc: 0.929684\n",
      "period: [46968 46969 46970 ... 70449 70450 70451] , the score is 0.9296839936215263\n",
      "############################################################ fold = 4 / 5\n",
      "####### cur time = 2019/09/22 08:56:18\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid_0's auc: 0.939739\n",
      "Early stopping, best iteration is:\n",
      "[755]\tvalid_0's auc: 0.940794\n",
      "period: [70452 70453 70454 ... 93932 93933 93934] , the score is 0.940793874242189\n",
      "############################################################ fold = 5 / 5\n",
      "####### cur time = 2019/09/22 08:57:38\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid_0's auc: 0.921469\n",
      "Early stopping, best iteration is:\n",
      "[649]\tvalid_0's auc: 0.922279\n",
      "period: [ 93935  93936  93937 ... 117415 117416 117417] , the score is 0.9222789093770793\n",
      "score_list_mean = 0.926490\n",
      "score full train = 0.919744\n",
      "simulation begin.\n",
      "simulation begin.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['C14'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/root/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/root/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-6-fdd1656f8c96>\", line 74, in local_special_black_merge\n    data_card = data_card_merged_online(train, test, key_id)\n  File \"<ipython-input-6-fdd1656f8c96>\", line 13, in data_card_merged_online\n    tr = train[used + ['isFraud']]\n  File \"/root/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\", line 2934, in __getitem__\n    raise_missing=True)\n  File \"/root/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1354, in _convert_to_indexer\n    return self._get_listlike_indexer(obj, axis, **kwargs)[1]\n  File \"/root/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1161, in _get_listlike_indexer\n    raise_missing=raise_missing)\n  File \"/root/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1252, in _validate_read_indexer\n    raise KeyError(\"{} not in index\".format(not_found))\nKeyError: \"['C14'] not in index\"\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-85c5298be53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold_rule_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_transaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-85c5298be53d>\u001b[0m in \u001b[0;36mthreshold_rule_selection\u001b[0;34m(tr)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"##################################threshold:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_rule_based_chosen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9bfc1b06b79f>\u001b[0m in \u001b[0;36mlocal_rule_based_chosen\u001b[0;34m(tr, threshold)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mlocal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_training_baseline_estimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mfraud_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_list1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_threshold_rule_research\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblack_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_black_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mfraud_data2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_list2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_threshold_rule_research\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_special_black_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mfraud_data3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_list3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_threshold_rule_research\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrey_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_grey_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mfraud_data4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrule_list4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_threshold_rule_research\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhite_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_white_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fdd1656f8c96>\u001b[0m in \u001b[0;36mtrain_threshold_rule_research\u001b[0;34m(tr, full_list, threshold, func)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mlocal_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_transaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_rule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"simulation begin.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'multiprocessing'\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mlocal_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ts\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mfraud_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['C14'] not in index\""
     ]
    }
   ],
   "source": [
    "def threshold_rule_selection(tr):\n",
    "    ans = pd.DataFrame([])\n",
    "    for i in [0.2, 0.5, 0.8]:\n",
    "        print(\"##################################threshold:\", i)\n",
    "        res = local_rule_based_chosen(tr, i)\n",
    "        ans = pd.concat([ans, res])\n",
    "    return ans\n",
    "\n",
    "final_result = threshold_rule_selection(train_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_score</th>\n",
       "      <th>boosted_score</th>\n",
       "      <th>boost_score</th>\n",
       "      <th>name</th>\n",
       "      <th>card_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900783</td>\n",
       "      <td>0.909399</td>\n",
       "      <td>8.616242e-03</td>\n",
       "      <td>[card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new, card1_card2_card3_card4_card5_card6_addr1_addr2_D1_new, D10_new_card1_card2_card3_card4_card5_card6_D1_new, D10_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, D15_new_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, card1_card2_card3_card4_card5_card6_C2_C4_C6_C8_C10_C12_D1_new, C1_C10_card1_card2_card3_card4_card5_card6_D1_new, card1_card2_card3_card4_card5_card6_C1_C3_C5_C7_C9_C11_D1_new, D2_new_card1_card2_card3_card4_card5_card6_addr1_addr2, C4_card1_card2_card3_card4_card5_card6_D1_new, C5_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_addr1_addr2]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909419</td>\n",
       "      <td>0.909420</td>\n",
       "      <td>1.473543e-07</td>\n",
       "      <td>[C14_card1_card2_card3_card4_card5_card6_D1_new]</td>\n",
       "      <td>special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909420</td>\n",
       "      <td>0.909420</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>[]</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.900783</td>\n",
       "      <td>0.902468</td>\n",
       "      <td>1.684784e-03</td>\n",
       "      <td>num    ratio  \\\n",
       "0  0.0  12722.0   \n",
       "0  0.0  12318.0   \n",
       "\n",
       "                                                                                                name  \\\n",
       "0              card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "0  card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "\n",
       "  card_cat  \n",
       "0    white  \n",
       "0    white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926634</td>\n",
       "      <td>0.933242</td>\n",
       "      <td>6.607443e-03</td>\n",
       "      <td>[card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new, card1_card2_card3_card4_card5_card6_addr1_addr2_D1_new, D10_new_card1_card2_card3_card4_card5_card6_D1_new, D10_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, D15_new_card1_card2_card3_card4_card5_card6_D1_new, D2_new_card1_card2_card3_card4_card5_card6_addr1_addr2, addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new, D4_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, C4_card1_card2_card3_card4_card5_card6_D1_new, C5_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_addr1_addr2]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933506</td>\n",
       "      <td>0.933559</td>\n",
       "      <td>5.270585e-05</td>\n",
       "      <td>[C12_card1_card2_card3_card4_card5_card6_D1_new, D2_new_card1_card2_card3_card4_card5_card6_addr1_addr2, D15_new_card1_card2_card3_card4_card5_card6_D1_new]</td>\n",
       "      <td>special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.933559</td>\n",
       "      <td>0.933611</td>\n",
       "      <td>5.189240e-05</td>\n",
       "      <td>[D11_new_card1_card2_card3_card4_card5_card6_D1_new]</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.926634</td>\n",
       "      <td>0.927144</td>\n",
       "      <td>5.098825e-04</td>\n",
       "      <td>num    ratio  \\\n",
       "0  7.0  15826.0   \n",
       "0  6.0  15287.0   \n",
       "\n",
       "                                                                                                name  \\\n",
       "0              card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "0  card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "\n",
       "  card_cat  \n",
       "0    white  \n",
       "0    white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.941366</td>\n",
       "      <td>0.941558</td>\n",
       "      <td>1.924965e-04</td>\n",
       "      <td>[D10_new_card1_card2_card3_card4_card5_card6_D1_new, C5_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, card1_card2_card3_card4_card5_card6_addr1_addr2_D1_new]</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.941643</td>\n",
       "      <td>0.941643</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>[]</td>\n",
       "      <td>special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941643</td>\n",
       "      <td>0.941643</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>[]</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941366</td>\n",
       "      <td>0.941422</td>\n",
       "      <td>5.566643e-05</td>\n",
       "      <td>num    ratio  \\\n",
       "0  25.0  13427.0   \n",
       "0   1.0  12965.0   \n",
       "\n",
       "                                                                                                name  \\\n",
       "0              card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "0  card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "\n",
       "  card_cat  \n",
       "0    white  \n",
       "0    white</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_score  boosted_score   boost_score  \\\n",
       "0       0.900783       0.909399  8.616242e-03   \n",
       "1       0.909419       0.909420  1.473543e-07   \n",
       "2       0.909420       0.909420  0.000000e+00   \n",
       "3       0.900783       0.902468  1.684784e-03   \n",
       "0       0.926634       0.933242  6.607443e-03   \n",
       "1       0.933506       0.933559  5.270585e-05   \n",
       "2       0.933559       0.933611  5.189240e-05   \n",
       "3       0.926634       0.927144  5.098825e-04   \n",
       "0       0.941366       0.941558  1.924965e-04   \n",
       "1       0.941643       0.941643  0.000000e+00   \n",
       "2       0.941643       0.941643  0.000000e+00   \n",
       "3       0.941366       0.941422  5.566643e-05   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 name  \\\n",
       "0  [card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new, card1_card2_card3_card4_card5_card6_addr1_addr2_D1_new, D10_new_card1_card2_card3_card4_card5_card6_D1_new, D10_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, D15_new_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, card1_card2_card3_card4_card5_card6_C2_C4_C6_C8_C10_C12_D1_new, C1_C10_card1_card2_card3_card4_card5_card6_D1_new, card1_card2_card3_card4_card5_card6_C1_C3_C5_C7_C9_C11_D1_new, D2_new_card1_card2_card3_card4_card5_card6_addr1_addr2, C4_card1_card2_card3_card4_card5_card6_D1_new, C5_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_addr1_addr2]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [C14_card1_card2_card3_card4_card5_card6_D1_new]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                              num    ratio  \\\n",
       "0  0.0  12722.0   \n",
       "0  0.0  12318.0   \n",
       "\n",
       "                                                                                                name  \\\n",
       "0              card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "0  card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "\n",
       "  card_cat  \n",
       "0    white  \n",
       "0    white     \n",
       "0                                                                                                                     [card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new, card1_card2_card3_card4_card5_card6_addr1_addr2_D1_new, D10_new_card1_card2_card3_card4_card5_card6_D1_new, D10_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, D15_new_card1_card2_card3_card4_card5_card6_D1_new, D2_new_card1_card2_card3_card4_card5_card6_addr1_addr2, addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new, D4_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, C4_card1_card2_card3_card4_card5_card6_D1_new, C5_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_addr1_addr2]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [C12_card1_card2_card3_card4_card5_card6_D1_new, D2_new_card1_card2_card3_card4_card5_card6_addr1_addr2, D15_new_card1_card2_card3_card4_card5_card6_D1_new]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [D11_new_card1_card2_card3_card4_card5_card6_D1_new]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                              num    ratio  \\\n",
       "0  7.0  15826.0   \n",
       "0  6.0  15287.0   \n",
       "\n",
       "                                                                                                name  \\\n",
       "0              card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "0  card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "\n",
       "  card_cat  \n",
       "0    white  \n",
       "0    white     \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [D10_new_card1_card2_card3_card4_card5_card6_D1_new, C5_card1_card2_card3_card4_card5_card6_D1_new, D4_new_card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14, card1_card2_card3_card4_card5_card6_addr1_addr2_D1_new]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                            num    ratio  \\\n",
       "0  25.0  13427.0   \n",
       "0   1.0  12965.0   \n",
       "\n",
       "                                                                                                name  \\\n",
       "0              card1_card2_card3_card4_card5_card6_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "0  card1_card2_card3_card4_card5_card6_addr1_addr2_C1_C2_C3_C4_C5_C6_C7_C8_C9_C10_C11_C12_C14_D1_new   \n",
       "\n",
       "  card_cat  \n",
       "0    white  \n",
       "0    white     \n",
       "\n",
       "  card_cat  \n",
       "0    black  \n",
       "1  special  \n",
       "2     grey  \n",
       "3    white  \n",
       "0    black  \n",
       "1  special  \n",
       "2     grey  \n",
       "3    white  \n",
       "0    black  \n",
       "1  special  \n",
       "2     grey  \n",
       "3    white  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "day_list =  [[col] + card_feature + ['D1_new'] for col in ['D11_new']]\n",
    "#plus D11_new out of research.\n",
    "grey_list = day_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_list = [[col] + card_feature + ['D1_new'] for col in ['C4', 'C5']]\n",
    "basis_list = [card_feature + addr_feature + c_feat + ['D1_new'],\n",
    "              card_feature + addr_feature + ['D1_new'],\n",
    "             \n",
    "             card_feature + ['C{}'.format(i) for i in range(1, 12, 2)] + ['D1_new'],\n",
    "             card_feature + ['C{}'.format(i) for i in range(2, 13, 2)] + ['D1_new']\n",
    "             ]\n",
    "second_list = [col + card_feature + ['D1_new'] for col in [['C1', 'C10'],\n",
    "                                                           ['C1', 'C2', 'C9', 'C10', 'C11', 'C12']] ]\n",
    "\n",
    "day_list =  [[col] + card_feature + ['D1_new'] for col in ['D10_new', 'D15_new']] +\\\n",
    "            [[col] + card_feature + addr_feature for col in ['D2_new', 'D4_new']] +\\\n",
    "            [[col] + card_feature + c_feat for col in ['D4_new', 'D10_new']]\n",
    "\n",
    "black_list = count_list + basis_list + second_list + day_list + addr_list\n",
    "\n",
    "count_list = [[col] + card_feature + ['D1_new'] for col in ['C12', 'C14']]\n",
    "day_list =  [[col] + card_feature + ['D1_new'] for col in ['D10_new', 'D15_new']] +\\\n",
    "            [[col] + card_feature + addr_feature for col in ['D2_new', 'D4_new']] +\\\n",
    "            [[col] + card_feature + c_feat for col in ['D4_new', 'D10_new']]\n",
    "        \n",
    "special_list = count_list + day_list + basis_list + addr_list\n",
    "\n",
    "count_list = [[col] + card_feature + ['D1_new'] for col in c_feat]\n",
    "basis_list = [card_feature + addr_feature + c_feat + ['D1_new'],\n",
    "              card_feature + addr_feature + ['D1_new'],\n",
    "             card_feature + ['C{}'.format(i) for i in range(1, 12, 2)] + ['D1_new'],\n",
    "             card_feature + ['C{}'.format(i) for i in range(2, 13, 2)]+ ['D1_new']\n",
    "              \n",
    "             ]\n",
    "\n",
    "day_list =  [[col] + card_feature + ['D1_new'] for col in ['D2_new', 'D11_new']] +\\\n",
    "             [[col] + card_feature + addr_feature for col in ['D2_new', 'D11_new']]\n",
    "#plus D11_new out of research.\n",
    "grey_list = basis_list + day_list + addr_list\n",
    "\n",
    "white_list = [card_feature + addr_feature + c_feat + ['D1_new'], card_feature + c_feat + ['D1_new']\n",
    "             ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
